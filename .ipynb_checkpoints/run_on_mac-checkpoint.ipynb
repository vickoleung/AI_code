{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagenet10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb666a9e587d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimagenet10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNet10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imagenet10'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from imagenet10 import ImageNet10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from config import *\n",
    "\n",
    "\n",
    "# Gathers the meta data for the images\n",
    "paths, classes = [], []\n",
    "for i, dir_ in enumerate(CLASS_LABELS):\n",
    "    for entry in os.scandir(ROOT_DIR + dir_):\n",
    "        if (entry.is_file()):\n",
    "            paths.append(entry.path)\n",
    "            classes.append(i)\n",
    "            \n",
    "data = {\n",
    "    'path': paths,\n",
    "    'class': classes\n",
    "}\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['path', 'class'])\n",
    "data_df = data_df.sample(frac=1).reset_index(drop=True) # Shuffles the data\n",
    "\n",
    "# See what the dataframe now contains\n",
    "print(\"Found\", len(data_df), \"images.\")\n",
    "# If you want to see the image meta data\n",
    "print(data_df.head())\n",
    "\n",
    "# Split the data into train and test sets and instantiate our new ImageNet10 objects.\n",
    "train_split = 0.80 # Defines the ratio of train/valid data.\n",
    "\n",
    "# valid_size = 1.0 - train_size\n",
    "train_size = int(len(data_df)*train_split)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.CenterCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(NORM_MEAN, NORM_STD),\n",
    "    ])\n",
    "\n",
    "dataset_train = ImageNet10(\n",
    "    df=data_df[:train_size],\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "dataset_valid = ImageNet10(\n",
    "    df=data_df[train_size:].reset_index(drop=True),\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=128,  # The number of samples in a batch\n",
    "    shuffle=True,\n",
    "    num_workers=0 \n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# See what you've loaded\n",
    "print(\"len(dataset_train)\", len(dataset_train))\n",
    "print(\"len(dataset_valid)\", len(dataset_valid))\n",
    "\n",
    "print(\"len(train_loader)\", len(train_loader))\n",
    "print(\"len(valid_loader)\", len(valid_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way\n",
    "class MyNewNetwork(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyNewNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3,32, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) # (128,128) -> (64,64)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32,64, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) # (64,64) -> (32,32)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64,128, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2)) # (32,32) -> (16,16)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(128*16*16, 128), nn.ReLU(),\n",
    "                                        nn.Linear(128, 64), nn.ReLU(),\n",
    "                        nn.Linear(64, num_classes))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.conv3(input)\n",
    "        input = input.reshape(input.size(0), -1) \n",
    "        input = self.classifier(input)\n",
    "\n",
    "        return input\n",
    "    \n",
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LinearNetwork, self).__init__()\n",
    "        \n",
    "        self.classfier = nn.Sequential(nn.Linear(128*10*10, num_classes))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.reshape(inputs.size(0), -1)\n",
    "        inputs = inputs.classfier(inputs)\n",
    "        \n",
    "        return inputs\n",
    "    \n",
    "    \n",
    "def stats(loader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            #images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)    # add in the number of labels in this minibatch\n",
    "            correct += (predicted == labels).sum().item()  # add in the number of correct labels\n",
    "            running_loss += loss\n",
    "            n += 1\n",
    "    return running_loss/n, correct/total \n",
    "\n",
    "\n",
    "def train(nepochs, model, train_loader, test_loader, loss_fn, optimizer):\n",
    "    statsrec = np.zeros((3,nepochs))\n",
    "\n",
    "    for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        n = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "                        \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs) # forward pass\n",
    "            loss = loss_fn(outputs, labels) # loss function\n",
    "            loss.backward() # backward\n",
    "            optimizer.step() #update params\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            n += 1\n",
    "\n",
    "        ltrn = running_loss/n\n",
    "        ltst, atst = stats(test_loader, model)\n",
    "        statsrec[:,epoch] = (ltrn, ltst, atst)\n",
    "        print(f\"epoch: {epoch} training loss: {ltrn: .3f}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "    \n",
    "    return statsrec, model\n",
    "\n",
    "\n",
    "def train1(nepochs, model, train_loader, test_loader, loss_fn, optimizer):\n",
    "    statsrec = np.zeros((3,nepochs))\n",
    "\n",
    "            \n",
    "    it = iter(train_loader)\n",
    "    inputs, labels = next(it)\n",
    "    \n",
    "    for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "                        \n",
    "            # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) # forward pass\n",
    "        loss = loss_fn(outputs, labels) # loss function\n",
    "        loss.backward() # backward\n",
    "        optimizer.step() #update params\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "\n",
    "        ltst, atst = stats(test_loader, model)\n",
    "        statsrec[:,epoch] = (running_loss, ltst, atst)\n",
    "        print(f\"epoch: {epoch} training loss: {running_loss: .3f}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "    \n",
    "    return statsrec, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 10\n",
    "model = MyNewNetwork(10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
